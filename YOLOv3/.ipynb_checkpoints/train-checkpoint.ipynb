{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-b6f8fce831ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0myolov3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mYOLOv3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mconfig\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcfg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'dataset'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import core.utils\n",
    "import tqdm\n",
    "from dataset import Dataset\n",
    "from yolov3 import YOLOv3, decode, compute_loss\n",
    "from config import cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = Dataset('train')\n",
    "logdir = './data/log'\n",
    "\n",
    "step_per_epoch = len(trainset)  #返回batch的数量，每一个epoch有这么多个batch\n",
    "global_steps = tf.Variable(1, trainable=False, dtype=tf.int64)  #1\n",
    "warmup_steps = cfg.TRAIN.WARMUP_EPOCHS * steps_per_epoch # 热身 2*num_batchs\n",
    "total_steps = cfg.TRAIN.EPOCHS * steps_per_epoch  #  30*num_batchs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = tf.keras.layers.Input([416,416,3])  #用来实例化一个keras张量\n",
    "conv_tensors = YOLOv3(input_tensor)    #输出[conv_sbbox, conv_mbbox, conv_lbbox] 每一个都是3*(NUM_CLASS + 5)\n",
    "output_tensors = []\n",
    "for i, conv_tensor in enumerate(conv_tensors):\n",
    "    pred_tensor = decode(conv_tensor, i)   #对YOLOv3的输出重新编码\n",
    "    output_tensors.append(conv_tensor)\n",
    "    output_tensors.append(pred_tensor)\n",
    "#output_tensors=[conv_sbbox, pred_tensor0, conv_mbbox, pred_tensor1, conv_lbbox, pred_tensor2]\n",
    "\n",
    "model = tf.keras.Model(input_tensor, output_tensors)  #tf.keras.Model的用法?????\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "if os.path.exists(logdir): \n",
    "    shutil.rmtree(logdir)\n",
    "    \n",
    "writer = tf.summary.create_file_writer(logdir)   #?????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(image_data, target):\n",
    "    '''\n",
    "    输入：image_data ==> batch_image  (batchsize, _, _, 3)\n",
    "    target ==> (batch_smaller_target, batch_medium_target, batch_larger_target)\n",
    "    例如：batch_smaller_target = batch_label_sbbox, batch_sbboxes  #元组（标签，边界框数据）\n",
    "    '''\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred_result = model(image_data, training=True)  #pred_result就是output_tensors\n",
    "        giou_loss = conf_loss = prob_loss = 0   ##后两个的损失(score, probability)\n",
    "        \n",
    "        #优化过程\n",
    "        for i in range(3):\n",
    "            conv, pred = pred_result[i*2], pred_result[i*2+1]  #YOLOv3的输出 ，YOLOv3的输出的重新编码\n",
    "            loss_items = compute_loss(pred, conv, *target[i], i)\n",
    "            giou_loss += loss_items[0]\n",
    "            conf_loss += loss_items[1]\n",
    "            prob_loss += loss_items[2]\n",
    "        \n",
    "        total_loss = giou_loss + conf_loss + prob_loss\n",
    "        gradients = tape.gradient(total_loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        tf.print(\"=> STEP %4d   lr: %.6f   giou_loss: %4.2f   conf_loss: %4.2f   \"\n",
    "                 \"prob_loss: %4.2f   total_loss: %4.2f\" %(global_steps, optimizer.lr.numpy(),\n",
    "                                                          giou_loss, conf_loss,\n",
    "                                                          prob_loss, total_loss))\n",
    "        \n",
    "        #跟新学习率\n",
    "        global_steps.assign_add(1)\n",
    "        if global_steps < warmup_steps:\n",
    "            lr = global_steps / warmup_steps * cfg.TRAIN.LR_INIT\n",
    "        else:\n",
    "            lr = cfg.TRAIN.LR_END + 0.5 * (cfg.TRAIN.LR_INIT - cfg.TRAIN.LR_END) * (\n",
    "                (1 + tf.cos((global_steps - warmup_steps) / (total_steps - warmup_steps) * np.pi))\n",
    "            )\n",
    "        optimizer.lr.assign(lr.numpy())\n",
    "        \n",
    "        #writing summary data\n",
    "        with writer.as_default():\n",
    "            tf.summary.scalar(\"lr\", optimizer.lr, step=global_steps)\n",
    "            tf.summary.scalar(\"loss/total_loss\", total_loss, step=global_steps)\n",
    "            tf.summary.scalar(\"loss/giou_loss\", giou_loss, step=global_steps)\n",
    "            tf.summary.scalar(\"loss/conf_loss\", conf_loss, step=global_steps)\n",
    "            tf.summary.scalar(\"loss/prob_loss\", prob_loss, step=global_steps)\n",
    "        writer.flush()           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(cfg.TRAIN.EPOCHS):\n",
    "    for image_data, target in trainset:  #类实例：Dataset的__next__方法，\n",
    "                                         #返回batch_image, (batch_smaller_target, batch_medium_target, batch_larger_target)\n",
    "                                         #batch_smaller_target = batch_label_sbbox, batch_sbboxes  #元组（标签，边界框数据）\n",
    "        train_step(image_data, target)\n",
    "    \n",
    "    model.save_weights(\"./myyolov3\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
