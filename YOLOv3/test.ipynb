{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import core.utils as utils\n",
    "from core.config import cfg\n",
    "from core.yolov3 import YOLOv3, decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE   = 416\n",
    "NUM_CLASS    = len(utils.read_class_names(cfg.YOLO.CLASSES))\n",
    "CLASSES      = utils.read_class_names(cfg.YOLO.CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_dir_path = '../mAP/predicted'\n",
    "ground_truth_dir_path = '../mAP/ground-truth'\n",
    "if os.path.exists(predicted_dir_path): shutil.rmtree(predicted_dir_path)  #如果有此文件，就删除改文件\n",
    "if os.path.exists(ground_truth_dir_path): shutil.rmtree(ground_truth_dir_path)\n",
    "if os.path.exists(cfg.TEST.DECTECTED_IMAGE_PATH): shutil.rmtree(cfg.TEST.DECTECTED_IMAGE_PATH)   #\"./data/detection/\"\n",
    "#新建文件夹\n",
    "os.mkdir(predicted_dir_path)    #os.mkdir()函数创建目录（创建一级目录）\n",
    "os.mkdir(ground_truth_dir_path)\n",
    "os.mkdir(cfg.TEST.DECTECTED_IMAGE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Model\n",
    "input_layer  = tf.keras.layers.Input([INPUT_SIZE, INPUT_SIZE, 3])\n",
    "feature_maps = YOLOv3(input_layer)\n",
    "\n",
    "bbox_tensors = []\n",
    "for i, fm in enumerate(feature_maps):\n",
    "    bbox_tensor = decode(fm, i)\n",
    "    bbox_tensors.append(bbox_tensor)\n",
    "\n",
    "model = tf.keras.Model(input_layer, bbox_tensors)\n",
    "model.load_weights(\"./myyolov3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#打开yymnist_test.txt测试文件，并将真实结果写入到ground-truth文件夹中，将预测结果写入到predicted文件件中\n",
    "with open(cfg.TEST.ANNOT_PATH, 'r') as annotation_file:    #\"./data/dataset/yymnist_test.txt\"\n",
    "    for num, line in enumerate(annotation_file):\n",
    "        annotation = line.strip().split()\n",
    "        image_path = annotation[0]\n",
    "        image_name = image_path.split('/')[-1]\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        bbox_data_gt = np.array([list(map(int, box.split(','))) for box in annotation[1:]])\n",
    "\n",
    "        if len(bbox_data_gt) == 0:\n",
    "            bboxes_gt=[]\n",
    "            classes_gt=[]\n",
    "        else:\n",
    "            bboxes_gt, classes_gt = bbox_data_gt[:, :4], bbox_data_gt[:, 4]\n",
    "        ground_truth_path = os.path.join(ground_truth_dir_path, str(num) + '.txt')\n",
    "\n",
    "        print('=> ground truth of %s:' % image_name)    \n",
    "        num_bbox_gt = len(bboxes_gt)\n",
    "        with open(ground_truth_path, 'w') as f:          #真实结果写入到ground-truth文件夹中\n",
    "            for i in range(num_bbox_gt):\n",
    "                class_name = CLASSES[classes_gt[i]]\n",
    "                xmin, ymin, xmax, ymax = list(map(str, bboxes_gt[i]))\n",
    "                bbox_mess = ' '.join([class_name, xmin, ymin, xmax, ymax]) + '\\n'\n",
    "                f.write(bbox_mess)\n",
    "                print('\\t' + str(bbox_mess).strip())\n",
    "#--------------------------------------------预测阶段------------------------------------------------------        \n",
    "        print('=> predict result of %s:' % image_name)  \n",
    "        predict_result_path = os.path.join(predicted_dir_path, str(num) + '.txt')\n",
    "        # Predict Process\n",
    "        image_size = image.shape[:2]\n",
    "        image_data = utils.image_preporcess(np.copy(image), [INPUT_SIZE, INPUT_SIZE])\n",
    "        image_data = image_data[np.newaxis, ...].astype(np.float32)\n",
    "\n",
    "        pred_bbox = model.predict(image_data)  #预测结果pred_bbox\n",
    "        pred_bbox = [tf.reshape(x, (-1, tf.shape(x)[-1])) for x in pred_bbox]\n",
    "        pred_bbox = tf.concat(pred_bbox, axis=0)\n",
    "        bboxes = utils.postprocess_boxes(pred_bbox, image_size, INPUT_SIZE, cfg.TEST.SCORE_THRESHOLD)  #\n",
    "        bboxes = utils.nms(bboxes, cfg.TEST.IOU_THRESHOLD, method='nms')   #非极大值抑制\n",
    "\n",
    "\n",
    "        if cfg.TEST.DECTECTED_IMAGE_PATH is not None:\n",
    "            image = utils.draw_bbox(image, bboxes)      #画出图像的识别出来的物体\n",
    "            cv2.imwrite(cfg.TEST.DECTECTED_IMAGE_PATH+image_name, image)\n",
    "\n",
    "        with open(predict_result_path, 'w') as f:    #将预测结果写入到predicted文件件中\n",
    "            for bbox in bboxes:\n",
    "                coor = np.array(bbox[:4], dtype=np.int32)\n",
    "                score = bbox[4]\n",
    "                class_ind = int(bbox[5])\n",
    "                class_name = CLASSES[class_ind]\n",
    "                score = '%.4f' % score\n",
    "                xmin, ymin, xmax, ymax = list(map(str, coor))\n",
    "                bbox_mess = ' '.join([class_name, score, xmin, ymin, xmax, ymax]) + '\\n'\n",
    "                f.write(bbox_mess)\n",
    "                print('\\t' + str(bbox_mess).strip())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
