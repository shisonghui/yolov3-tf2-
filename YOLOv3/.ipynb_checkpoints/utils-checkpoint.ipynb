{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import random\n",
    "import colorsys\n",
    "import numpy as np\n",
    "from core.config import cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def load_weights(model, weights_file):\n",
    "    \"\"\"\n",
    "    I agree that this code is very ugly, but I don’t know any better way of doing it.\n",
    "    \"\"\"\n",
    "    wf = open(weights_file, 'rb')\n",
    "    major, minor, revision, seen, _ = np.fromfile(wf, dtype=np.int32, count=5)\n",
    "\n",
    "    j = 0\n",
    "    for i in range(75):\n",
    "        conv_layer_name = 'conv2d_%d' %i if i > 0 else 'conv2d'\n",
    "        bn_layer_name = 'batch_normalization_%d' %j if j > 0 else 'batch_normalization'\n",
    "\n",
    "        conv_layer = model.get_layer(conv_layer_name)\n",
    "        filters = conv_layer.filters\n",
    "        k_size = conv_layer.kernel_size[0]\n",
    "        in_dim = conv_layer.input_shape[-1]\n",
    "\n",
    "        if i not in [58, 66, 74]:\n",
    "            # darknet weights: [beta, gamma, mean, variance]\n",
    "            bn_weights = np.fromfile(wf, dtype=np.float32, count=4 * filters)\n",
    "            # tf weights: [gamma, beta, mean, variance]\n",
    "            bn_weights = bn_weights.reshape((4, filters))[[1, 0, 2, 3]]\n",
    "            bn_layer = model.get_layer(bn_layer_name)\n",
    "            j += 1\n",
    "        else:\n",
    "            conv_bias = np.fromfile(wf, dtype=np.float32, count=filters)\n",
    "\n",
    "        # darknet shape (out_dim, in_dim, height, width)\n",
    "        conv_shape = (filters, in_dim, k_size, k_size)\n",
    "        conv_weights = np.fromfile(wf, dtype=np.float32, count=np.product(conv_shape))\n",
    "        # tf shape (height, width, in_dim, out_dim)\n",
    "        conv_weights = conv_weights.reshape(conv_shape).transpose([2, 3, 1, 0])\n",
    "\n",
    "        if i not in [58, 66, 74]:\n",
    "            conv_layer.set_weights([conv_weights])\n",
    "            bn_layer.set_weights(bn_weights)\n",
    "        else:\n",
    "            conv_layer.set_weights([conv_weights, conv_bias])\n",
    "\n",
    "    assert len(wf.read()) == 0, 'failed to read all data'\n",
    "    wf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def read_calss_names(classes_path):\n",
    "    '''loads class name from a file'''\n",
    "    names = {}\n",
    "    with open(classes_path, 'r') as data:\n",
    "        for ID, name in enumerate(data):\n",
    "            names[ID] = name.stripp('\\n')\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_anchors(anchors_path):\n",
    "    with open(anchors_path) as f:\n",
    "        anchors = f.readline()\n",
    "    anchors = np.array(anchors.split(','),dtype=np.float32)\n",
    "    return anchors.reshape(3,3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def image_preporcess(image, target_size, gt_boxes=None):\n",
    "    '''\n",
    "    gt_boxes.shape=(None, 5)  (x, y, w, h, class)\n",
    "    array([[358, 222, 400, 264,   0],\n",
    "       [208, 147, 264, 203,   1],\n",
    "       [347, 313, 375, 341,   3],\n",
    "       [115,  49, 171, 105,   1]])\n",
    "    '''\n",
    "    ih, iw    = target_size  #要改的大小\n",
    "    h,  w, _  = image.shape  #图像实际大小\n",
    "    \n",
    "    scale = min(iw/w, ih/h)\n",
    "    nw, nh  = int(scale * w), int(scale * h)\n",
    "    image_resized = cv2.resize(image, (nw, nh))  #改变图像大小\n",
    "    \n",
    "    image_paded = np.full(shape=[ih, iw, 3], fill_value= 128.0)\n",
    "    dw, dh = (iw - nw) // 2, (ih-nh) // 2\n",
    "    image_paded[dh:nh+dh, dw:nw+dw, :] = image_resized\n",
    "    image_paded = image_paded / 255.  #shape (ih,iw,3)\n",
    "    \n",
    "    if gt_boxes is None:\n",
    "        return image_paded\n",
    "    else:   #bboxes的大小也要相应的改变\n",
    "        gt_boxes[:, [0, 2]] = gt_boxes[:, [0, 2]] * scale + dw\n",
    "        gt_boxes[:, [1, 3]] = gt_boxes[:, [1, 3]] * scale + dh\n",
    "        return image_paded, gt_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def postprocess_boxes(pred_bbox, org_img_shape, input_size, score_threshold):\n",
    "    valid_scale = [0, np.inf]\n",
    "    pred_bbox = np.array(pred_bbox)\n",
    "    \n",
    "    pred_xywh = pred_bbox[:,0:4]\n",
    "    pred_conf = pred_bbox[:, 4]\n",
    "    pred_prob = pred_bbox[:, 5:]\n",
    "    # # (1) (x, y, w, h) --> (xmin, ymin, xmax, ymax)\n",
    "    pred_coor = np.concatenate([pred_xywh[:, :2] - pred_xywh[:, 2:] * 0.5,\n",
    "                                pred_xywh[:, :2] + pred_xywh[:, 2:] * 0.5], axis=-1)\n",
    "    # # (2) (xmin, ymin, xmax, ymax) -> (xmin_org, ymin_org, xmax_org, ymax_org)\n",
    "    org_h, org_w = org_img_shape\n",
    "    resize_ratio = min(input_size / org_w, input_size / org_h)\n",
    "\n",
    "    dw = (input_size - resize_ratio * org_w) / 2\n",
    "    dh = (input_size - resize_ratio * org_h) / 2\n",
    "\n",
    "    pred_coor[:, 0::2] = 1.0 * (pred_coor[:, 0::2] - dw) / resize_ratio    #1,3列\n",
    "    pred_coor[:, 1::2] = 1.0 * (pred_coor[:, 1::2] - dh) / resize_ratio    #2,4列\n",
    "    \n",
    "    # # (3) clip some boxes those are out of range\n",
    "    pred_coor = np.concatenate([np.maximum(pred_coor[:, :2], [0, 0]),\n",
    "                                np.minimum(pred_coor[:, 2:], [org_w - 1, org_h - 1])], axis=-1)\n",
    "    invalid_mask = np.logical_or((pred_coor[:, 0] > pred_coor[:, 2]), (pred_coor[:, 1] > pred_coor[:, 3]))#找到超出范围的边框\n",
    "    pred_coor[invalid_mask] = 0  #删除超出范围的边框\n",
    "    \n",
    "    # # (4) discard some invalid boxes\n",
    "    bboxes_scale = np.sqrt(np.multiply.reduce(pred_coor[:, 2:4] - pred_coor[:, 0:2], axis=-1))\n",
    "    scale_mask = np.logical_and((valid_scale[0] < bboxes_scale), (bboxes_scale < valid_scale[1]))\n",
    "    \n",
    "    # # (5) discard some boxes with low scores\n",
    "    classes = np.argmax(pred_prob, axis=-1)\n",
    "    scores = pred_conf * pred_prob[np.arange(len(pred_coor)), classes]\n",
    "    score_mask = scores > score_threshold\n",
    "    mask = np.logical_and(scale_mask, score_mask)\n",
    "    coors, scores, classes = pred_coor[mask], scores[mask], classes[mask]\n",
    "    \n",
    "    return np.concatenate([coors, scores[:, np.newaxis], classes[:, np.newaxis]], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def bboxes_iou(boxes1, boxes2):\n",
    "\n",
    "    boxes1 = np.array(boxes1)\n",
    "    boxes2 = np.array(boxes2)\n",
    "\n",
    "    boxes1_area = (boxes1[..., 2] - boxes1[..., 0]) * (boxes1[..., 3] - boxes1[..., 1])\n",
    "    boxes2_area = (boxes2[..., 2] - boxes2[..., 0]) * (boxes2[..., 3] - boxes2[..., 1])\n",
    "\n",
    "    left_up       = np.maximum(boxes1[..., :2], boxes2[..., :2])\n",
    "    right_down    = np.minimum(boxes1[..., 2:], boxes2[..., 2:])\n",
    "\n",
    "    inter_section = np.maximum(right_down - left_up, 0.0)\n",
    "    inter_area    = inter_section[..., 0] * inter_section[..., 1]\n",
    "    union_area    = boxes1_area + boxes2_area - inter_area\n",
    "    ious          = np.maximum(1.0 * inter_area / union_area, np.finfo(np.float32).eps)  #1.1920929e-07\n",
    "\n",
    "    return ious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def nms(bboxes, iou_threshold, sigma=0.3, method='nms'):\n",
    "    '''\n",
    "    非极大值抑制\n",
    "    bboxes: (xmin, ymin, xmax, ymax, score, class) 边框左上角和右下角的点\n",
    "    '''\n",
    "    classes_in_img = list(set(bboxes[:,5]))  #图像中有多少种类别出现，用set集合\n",
    "    best_bboxes = []  #用来装最好的边框\n",
    "    \n",
    "    for cls in classes_in_img:    #对每一类单独进行分析\n",
    "        cls_mask = (bboxes[:, 5] == cls)\n",
    "        cls_bboxes = bboxes[cls_mask]\n",
    "        \n",
    "        while len(cls_bboxes) > 0:\n",
    "            max_ind = np.argmax(cls_bboxes[:, 4])\n",
    "            best_bbox = cls_bboxes[max_ind]\n",
    "            best_bboxes.append(best_bbox)\n",
    "            cls_bboxes = np.concatenate([cls_bboxes[:max_ind],cls_bboxes[max_ind+1 :]])  #cls_bboxes除去分数最大的那个边框\n",
    "            iou = bboxes_iou(best_bbox[np.newaxis, :4], cls_bboxes[:, :4])\n",
    "            weight = np.ones((len(iou),), dtype=np.float32)\n",
    "        \n",
    "            assert method in ['nms', 'soft-nms']\n",
    "            \n",
    "            if method == 'nms':\n",
    "                iou_mask = iou > iou_threshold    #小于iou_threshold的边框下一次循环继续处理\n",
    "                weight[iou_mask] = 0.0\n",
    "                \n",
    "            if method == 'soft-nms':\n",
    "                weight = np.exp(-(1.0 * iou ** 2 / sigma))\n",
    "                \n",
    "            cls_bboxes[:, 4] = cls_bboxes[:, 4] * weight   #大于iou_threshold的那些边框的分数将被变为0\n",
    "            score_mask = cls_bboxes[:, 4] > 0.\n",
    "            cls_bboxes = cls_bboxes[score_mask]    #除去iou大于iou_threshold的那些边框\n",
    "            \n",
    "    return best_bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def draw_bbox(image, bboxes, classes=read_class_names(cfg.YOLO.CLASSES), show_label=True):\n",
    "    \"\"\"\n",
    "    bboxes: [x_min, y_min, x_max, y_max, probability, cls_id] format coordinates.\n",
    "    \"\"\"\n",
    "    num_classes = len(classes)\n",
    "    image_h, image_w, _ = image.shape\n",
    "    hsv_tuples = [(1.0 * x / num_classes, 1., 1.) for x in range(num_classes)]\n",
    "    colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "    colors = list(map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)), colors))\n",
    "\n",
    "    random.seed(0)\n",
    "    random.shuffle(colors)\n",
    "    random.seed(None)\n",
    "\n",
    "    for i, bbox in enumerate(bboxes):\n",
    "        coor = np.array(bbox[:4], dtype=np.int32)\n",
    "        fontScale = 0.5\n",
    "        score = bbox[4]\n",
    "        class_ind = int(bbox[5])\n",
    "        bbox_color = colors[class_ind]\n",
    "        bbox_thick = int(0.6 * (image_h + image_w) / 600)\n",
    "        c1, c2 = (coor[0], coor[1]), (coor[2], coor[3])\n",
    "        cv2.rectangle(image, c1, c2, bbox_color, bbox_thick)\n",
    "\n",
    "        if show_label:\n",
    "            bbox_mess = '%s: %.2f' % (classes[class_ind], score)\n",
    "            t_size = cv2.getTextSize(bbox_mess, 0, fontScale, thickness=bbox_thick//2)[0]\n",
    "            cv2.rectangle(image, c1, (c1[0] + t_size[0], c1[1] - t_size[1] - 3), bbox_color, -1)  # filled\n",
    "\n",
    "            cv2.putText(image, bbox_mess, (c1[0], c1[1]-2), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        fontScale, (0, 0, 0), bbox_thick//2, lineType=cv2.LINE_AA)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7572115384615384\n",
      "315\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "import numpy as np\n",
    "\n",
    "ih, iw    = 315,315  #要改的大小\n",
    "h,  w  = 416,416  #图像实际大小\n",
    "\n",
    "scale = min(iw/w, ih/h)\n",
    "print(scale)\n",
    "nw, nh  = int(scale * w), int(scale * h)\n",
    "print(nw)\n",
    "image_resized = np.ones((nw, nh))  #改变图像大小\n",
    "\n",
    "image_paded = np.full(shape=[ih, iw], fill_value= 128.0)\n",
    "dw, dh = (iw - nw) // 2, (ih-nh) // 2\n",
    "image_paded[dh:nh+dh, dw:nw+dw] = image_resized\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#anno = \"E:\\TensorFlow2.0-Examples-master\\TensorFlow2.0-Examples-master\\4-Object_Detection\\YOLOV3\\data\\dataset\\train\\000001.jpg 358,222,400,264,0 208,147,264,203,1 347,313,375,341,3 115,49,171,105,1\"\n",
    "#line = anno.strip().split(' ')\n",
    "#gt_boxes = np.array([list(map(int, box.split(','))) for box in line[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[358, 222, 400, 264,   0],\n",
       "       [208, 147, 264, 203,   1],\n",
       "       [347, 313, 375, 341,   3],\n",
       "       [115,  49, 171, 105,   1]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gt_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gt_boxes[:, [0, 2]] = gt_boxes[:, [0, 2]] * scale + dw\n",
    "#gt_boxes[:, [1, 3]] = gt_boxes[:, [1, 3]] * scale + dh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[271, 168, 302, 199,   0],\n",
       "       [157, 111, 199, 153,   1],\n",
       "       [262, 237, 283, 258,   3],\n",
       "       [ 87,  37, 129,  79,   1]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gt_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[286.5 183.5  31.   31. ]\n",
      "[[35.8125   22.9375    3.875     3.875   ]\n",
      " [17.90625  11.46875   1.9375    1.9375  ]\n",
      " [ 8.953125  5.734375  0.96875   0.96875 ]]\n",
      "[178. 132.  42.  42.]\n",
      "[[22.25   16.5     5.25    5.25  ]\n",
      " [11.125   8.25    2.625   2.625 ]\n",
      " [ 5.5625  4.125   1.3125  1.3125]]\n",
      "[272.5 247.5  21.   21. ]\n",
      "[[34.0625   30.9375    2.625     2.625   ]\n",
      " [17.03125  15.46875   1.3125    1.3125  ]\n",
      " [ 8.515625  7.734375  0.65625   0.65625 ]]\n",
      "[108.  58.  42.  42.]\n",
      "[[13.5     7.25    5.25    5.25  ]\n",
      " [ 6.75    3.625   2.625   2.625 ]\n",
      " [ 3.375   1.8125  1.3125  1.3125]]\n"
     ]
    }
   ],
   "source": [
    "#strides = np.array([8, 16, 32])\n",
    "#for bbox in gt_boxes:\n",
    "#    bbox_coor = bbox[:4]\n",
    "#    bbox_xywh = np.concatenate([(bbox_coor[2:] + bbox_coor[:2]) * 0.5, bbox_coor[2:] - bbox_coor[:2]], axis=-1)\n",
    "#    print(bbox_xywh)\n",
    "#    bbox_xywh_scaled = 1.0 * bbox_xywh[np.newaxis, :] / strides[:, np.newaxis]\n",
    " #   print(bbox_xywh_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bbox_xywh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gt_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#invalid_mask = np.logical_or((gt_boxes[:, 0] < gt_boxes[:, 2]), (gt_boxes[:, 1] > gt_boxes[:, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#invalid_mask = [ False,  True,  False,  True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(gt_boxes[:, 0] < gt_boxes[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(gt_boxes[:, 1] > gt_boxes[:, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gt_boxes[invalid_mask] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[358, 222, 400, 264,   0],\n",
       "       [  0,   0,   0,   0,   0],\n",
       "       [347, 313, 375, 341,   3],\n",
       "       [  0,   0,   0,   0,   0]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gt_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gt_boxes = gt_boxes[invalid_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[157, 111, 199, 153,   1],\n",
       "       [ 87,  37, 129,  79,   1]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gt_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
